{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Triplet Loss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL31JSCBk8E5"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy import spatial\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.config.run_functions_eagerly(False)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-pyWaFbuy77"
      },
      "source": [
        "# !curl -LO https://raw.githubusercontent.com/MohamadMerchant/SNLI/master/data.tar.gz\n",
        "# !tar -xvzf data.tar.gz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px24Ss-4k8CO"
      },
      "source": [
        "df_train = pd.read_csv('data/SNLI/train.csv')\n",
        "df_dev = pd.read_csv('data/SNLI/dev.csv')\n",
        "df_test = pd.read_csv('data/SNLI/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yvfz_3xjzeTk",
        "outputId": "bbdb7103-e111-4f3b-e0e6-8d76843abc23"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      similarity                                          sentence1  \\\n",
              "0        neutral  This church choir sings to the masses as they ...   \n",
              "1     entailment  This church choir sings to the masses as they ...   \n",
              "2  contradiction  This church choir sings to the masses as they ...   \n",
              "3        neutral  A woman with a green headscarf, blue shirt and...   \n",
              "4     entailment  A woman with a green headscarf, blue shirt and...   \n",
              "\n",
              "                               sentence2  \n",
              "0  The church has cracks in the ceiling.  \n",
              "1        The church is filled with song.  \n",
              "2    A choir singing at a baseball game.  \n",
              "3                    The woman is young.  \n",
              "4               The woman is very happy.  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church has cracks in the ceiling.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entailment</td>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>The church is filled with song.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>This church choir sings to the masses as they ...</td>\n",
              "      <td>A choir singing at a baseball game.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is young.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entailment</td>\n",
              "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
              "      <td>The woman is very happy.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jzE6j4WPlDn_",
        "outputId": "7a050078-6012-4de5-fe3b-60f85ecd7e5b"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      similarity                                          sentence1  \\\n",
              "0        neutral  A person on a horse jumps over a broken down a...   \n",
              "1  contradiction  A person on a horse jumps over a broken down a...   \n",
              "2     entailment  A person on a horse jumps over a broken down a...   \n",
              "3        neutral              Children smiling and waving at camera   \n",
              "4     entailment              Children smiling and waving at camera   \n",
              "\n",
              "                                           sentence2  \n",
              "0  A person is training his horse for a competition.  \n",
              "1      A person is at a diner, ordering an omelette.  \n",
              "2                  A person is outdoors, on a horse.  \n",
              "3                  They are smiling at their parents  \n",
              "4                         There are children present  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entailment</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entailment</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>There are children present</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwh35DXrx3kx"
      },
      "source": [
        "similarity_map = {\n",
        "    'neutral': np.nan,\n",
        "    'contradiction': 0,\n",
        "    'entailment': 1,\n",
        "    '-': np.nan\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlnAH2eJyNd0"
      },
      "source": [
        "df_train['similarity'] = df_train['similarity'].apply(lambda column: similarity_map[column])\n",
        "df_dev['similarity'] = df_dev['similarity'].apply(lambda column: similarity_map[column])\n",
        "df_test['similarity'] = df_test['similarity'].apply(lambda column: similarity_map[column])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDZU1-cDyYvB"
      },
      "source": [
        "df_train.dropna(axis=0, inplace=True)\n",
        "df_dev.dropna(axis=0, inplace=True)\n",
        "df_test.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NZ_RQZFdyfG0",
        "outputId": "dee7aee6-4220-4c6f-b503-cab6f81c5019"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   similarity                                          sentence1  \\\n",
              "1         1.0  Two women are embracing while holding to go pa...   \n",
              "2         0.0  Two women are embracing while holding to go pa...   \n",
              "3         1.0  Two young children in blue jerseys, one with t...   \n",
              "5         0.0  Two young children in blue jerseys, one with t...   \n",
              "6         0.0  A man selling donuts to a customer during a wo...   \n",
              "\n",
              "                                        sentence2  \n",
              "1                 Two woman are holding packages.  \n",
              "2            The men are fighting outside a deli.  \n",
              "3  Two kids in numbered jerseys wash their hands.  \n",
              "5             Two kids in jackets walk to school.  \n",
              "6      A woman drinks her coffee in a small cafe.  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>Two woman are holding packages.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>The men are fighting outside a deli.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Two young children in blue jerseys, one with t...</td>\n",
              "      <td>Two kids in jackets walk to school.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>A man selling donuts to a customer during a wo...</td>\n",
              "      <td>A woman drinks her coffee in a small cafe.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186PEIeXymO1",
        "outputId": "e9d40256-a8f6-44eb-93a6-a8fe80335355"
      },
      "source": [
        "df_train.similarity.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    183414\n",
              "0.0    183185\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faWTxrTnzJ4L",
        "outputId": "b71b0705-5f66-450b-ee56-121ae28c961f"
      },
      "source": [
        "df_dev.similarity.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    3329\n",
              "0.0    3278\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v83zxdyzqG0",
        "outputId": "fadc43e1-b6a0-48a9-84bb-4546fc43ff87"
      },
      "source": [
        "df_test.similarity.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    3368\n",
              "0.0    3237\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNmoYdN4qjQi"
      },
      "source": [
        "def clean_word(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r'[^a-zA-Z ]', '', sentence)\n",
        "    return sentence"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPhfMLdbqjN9"
      },
      "source": [
        "df_train['sentence1'] = df_train['sentence1'].apply(clean_word)\n",
        "df_train['sentence2'] = df_train['sentence2'].apply(clean_word)\n",
        "\n",
        "df_dev['sentence1'] = df_dev['sentence1'].apply(clean_word)\n",
        "df_dev['sentence2'] = df_dev['sentence2'].apply(clean_word)\n",
        "\n",
        "df_test['sentence1'] = df_test['sentence1'].apply(clean_word)\n",
        "df_test['sentence2'] = df_test['sentence2'].apply(clean_word)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GwhtE6mXrvxR",
        "outputId": "201efa76-02be-405b-ee1f-848b2da39733"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   similarity                                          sentence1  \\\n",
              "1         1.0  two women are embracing while holding to go pa...   \n",
              "2         0.0  two women are embracing while holding to go pa...   \n",
              "3         1.0  two young children in blue jerseys one with th...   \n",
              "5         0.0  two young children in blue jerseys one with th...   \n",
              "6         0.0  a man selling donuts to a customer during a wo...   \n",
              "\n",
              "                                       sentence2  \n",
              "1                 two woman are holding packages  \n",
              "2            the men are fighting outside a deli  \n",
              "3  two kids in numbered jerseys wash their hands  \n",
              "5             two kids in jackets walk to school  \n",
              "6      a woman drinks her coffee in a small cafe  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>two women are embracing while holding to go pa...</td>\n",
              "      <td>two woman are holding packages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>two women are embracing while holding to go pa...</td>\n",
              "      <td>the men are fighting outside a deli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>two young children in blue jerseys one with th...</td>\n",
              "      <td>two kids in numbered jerseys wash their hands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>two young children in blue jerseys one with th...</td>\n",
              "      <td>two kids in jackets walk to school</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>a man selling donuts to a customer during a wo...</td>\n",
              "      <td>a woman drinks her coffee in a small cafe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrVPBjE3YC8Z"
      },
      "source": [
        "# df_train = df_train[:10000]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q36ypWJkBbE"
      },
      "source": [
        "def create_dataset(df):\n",
        "    unq_anchors = df['sentence1'].unique()\n",
        "    anchors = []\n",
        "    positives = []\n",
        "    negatives = []\n",
        "    for a in unq_anchors:\n",
        "        pos = df.loc[(df['sentence1'] == a) & (df['similarity'] == 1)]\n",
        "        neg = df.loc[(df['sentence1'] == a) & (df['similarity'] == 0)]\n",
        "        positive_values = pos['sentence2'].values\n",
        "        negative_values = neg['sentence2'].values\n",
        "        if len(pos) <= len(neg):\n",
        "            for idx in range(len(pos)):\n",
        "                anchors.append(a)\n",
        "                positives.append(positive_values[idx])\n",
        "                negatives.append(negative_values[idx])\n",
        "        elif len(pos) > len(neg):\n",
        "            extra_negs = df.loc[(df['sentence1'] != a)]\n",
        "            extra_neg_values = extra_negs['sentence2'].values\n",
        "            negative_values = list(negative_values) + list(extra_neg_values[:(len(pos)-len(neg))+1])\n",
        "            for idx in range(len(pos)):\n",
        "                anchors.append(a)\n",
        "                positives.append(positive_values[idx])\n",
        "                negatives.append(negative_values[idx])\n",
        "    return anchors, positives, negatives"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTFeuFIiBxbT"
      },
      "source": [
        "# train_anchors, train_positives, train_negatives = create_dataset(df_train[:10000])\n",
        "# dev_anchors, dev_positives, dev_negatives = create_dataset(df_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gWfExipkDW-"
      },
      "source": [
        "def tokenize(sentences):\n",
        "    tokens = []\n",
        "    for sentence in sentences:\n",
        "        tokens.append(word_tokenize(sentence))\n",
        "    return tokens\n",
        "\n",
        "def stem_word(sentences):\n",
        "    tokens = []\n",
        "    stemmer = PorterStemmer()\n",
        "    for sentence in sentences:\n",
        "        sentence_tokens = []\n",
        "        for word in sentence:\n",
        "            sentence_tokens.append(stemmer.stem(word))\n",
        "        tokens.append(sentence_tokens)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def remove_stopwords(sentences):\n",
        "    tokens = []\n",
        "    stop = stopwords.words('english')\n",
        "    for sentence in sentences:\n",
        "        new_sen = []\n",
        "        for word in sentence:\n",
        "            if word not in stop:\n",
        "                new_sen.append(word)\n",
        "        tokens.append(new_sen)\n",
        "    return tokens\n",
        "\n",
        "def flatten(item_list):\n",
        "    return [item for sublist in item_list for item in sublist]\n",
        "\n",
        "def create_vocabulary(anchor, positive, negative):\n",
        "    anchor = set(flatten(anchor))\n",
        "    positive = set(flatten(positive))\n",
        "    negative = set(flatten(negative))\n",
        "    vocab = anchor.union(positive).union(negative)\n",
        "    return sorted(list(vocab))\n",
        "\n",
        "def create_mappings(vocab):\n",
        "    word2idx = {word:idx+2 for idx,word in enumerate(vocab)}\n",
        "    idx2word = {idx+2:word for idx, word in enumerate(vocab)}\n",
        "    return word2idx, idx2word\n",
        "\n",
        "def map_to_token(map_dict, tokens):\n",
        "    all_tokens = []\n",
        "    for sentence in tokens:\n",
        "        sentence_tokens = []\n",
        "        for word in sentence:\n",
        "            if word in map_dict.keys():\n",
        "                sentence_tokens.append(map_dict[word])\n",
        "            else:\n",
        "                sentence_tokens.append(1)\n",
        "        all_tokens.append(sentence_tokens)\n",
        "    return all_tokens"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZZBR56vkDUJ"
      },
      "source": [
        "# train_anchor_tokens = tokenize(train_anchors)\n",
        "# train_positive_tokens = tokenize(train_positives)\n",
        "# train_negative_tokens = tokenize(train_negatives)\n",
        "\n",
        "# train_anchor_tokens = remove_stopwords(train_anchor_tokens)\n",
        "# train_positive_tokens = remove_stopwords(train_positive_tokens)\n",
        "# train_negative_tokens = remove_stopwords(train_negative_tokens)\n",
        "\n",
        "# train_anchor_tokens = stem_word(train_anchor_tokens)\n",
        "# train_positive_tokens= stem_word(train_positive_tokens)\n",
        "# train_negative_tokens = stem_word(train_negative_tokens)\n",
        "\n",
        "\n",
        "# dev_anchor_tokens = tokenize(dev_anchors)\n",
        "# dev_positive_tokens = tokenize(dev_positives)\n",
        "# dev_negative_tokens = tokenize(dev_negatives)\n",
        "\n",
        "# dev_anchor_tokens = remove_stopwords(dev_anchor_tokens)\n",
        "# dev_positive_tokens = remove_stopwords(dev_positive_tokens)\n",
        "# dev_negative_tokens = remove_stopwords(dev_negative_tokens)\n",
        "\n",
        "# dev_anchor_tokens = stem_word(dev_anchor_tokens)\n",
        "# dev_positive_tokens= stem_word(dev_positive_tokens)\n",
        "# dev_negative_tokens = stem_word(dev_negative_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiCNqYdgkDRZ"
      },
      "source": [
        "# vocab = create_vocabulary(train_anchor_tokens, train_positive_tokens, train_negative_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJoxHdk7kDO5"
      },
      "source": [
        "# word2idx, idx2word = create_mappings(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up0Wfxc5kQVs"
      },
      "source": [
        "# train_anchor_maps = map_to_token(word2idx, train_anchor_tokens)\n",
        "# train_positive_maps = map_to_token(word2idx, train_positive_tokens)\n",
        "# train_negative_maps = map_to_token(word2idx, train_negative_tokens)\n",
        "\n",
        "# dev_anchor_maps = map_to_token(word2idx, dev_anchor_tokens)\n",
        "# dev_positive_maps = map_to_token(word2idx, dev_positive_tokens)\n",
        "# dev_negative_maps = map_to_token(word2idx, dev_negative_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciE5cAeyEX9w"
      },
      "source": [
        "# anchor_train = pad_sequences(train_anchor_maps, maxlen=50)\n",
        "# positive_train = pad_sequences(train_positive_maps, maxlen=50)\n",
        "# negative_train = pad_sequences(train_negative_maps, maxlen=50)\n",
        "\n",
        "# anchor_dev = pad_sequences(dev_anchor_maps, maxlen=50)\n",
        "# positive_dev = pad_sequences(dev_positive_maps, maxlen=50)\n",
        "# negative_dev = pad_sequences(dev_negative_maps, maxlen=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUGU7-EoEX7H"
      },
      "source": [
        "# anchor_train = np.array(anchor_train, dtype='object').astype('float')\n",
        "# positive_train = np.array(positive_train, dtype='object').astype('float')\n",
        "# negative_train = np.array(negative_train, dtype='object').astype('float')\n",
        "\n",
        "# anchor_dev = np.array(anchor_dev, dtype='object').astype('float')\n",
        "# positive_dev = np.array(positive_dev, dtype='object').astype('float')\n",
        "# negative_dev = np.array(negative_dev, dtype='object').astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kttoL5L3EX4o"
      },
      "source": [
        "# y_train = np.ones((anchor_train.shape[0],1), dtype='float')\n",
        "# y_dev = np.ones((anchor_dev.shape[0],1), dtype='float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GS8idRhkQTL"
      },
      "source": [
        "def identity_loss(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "def triplet_loss(y_true,y_pred, alpha = 0.25):\n",
        "    anchor = y_pred[:,:128]\n",
        "    positive = y_pred[:,128:128*2]\n",
        "    negative = y_pred[:,-128:]\n",
        "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
        "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
        "    basic_loss = pos_dist-neg_dist+alpha\n",
        "    loss = K.maximum(basic_loss,0.0)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ATf2RN8kQQx"
      },
      "source": [
        "siamese_model = models.Sequential()\n",
        "siamese_model.add(layers.Embedding(input_dim=len(vocab)+2, output_dim=256))\n",
        "siamese_model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True)))\n",
        "siamese_model.add(layers.GlobalAveragePooling1D())\n",
        "siamese_model.add(layers.Dense(128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xxxv9f1kUls",
        "outputId": "5a66d63b-f5d0-4e70-e4c5-9bc960099389"
      },
      "source": [
        "siamese_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 256)         1059840   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         1050624   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "=================================================================\n",
            "Total params: 2,176,128\n",
            "Trainable params: 2,176,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qQq9XCmkUjO"
      },
      "source": [
        "anchor_input = keras.Input(shape=(50,))\n",
        "positive_input = keras.Input(shape=(50,))\n",
        "negative_input = keras.Input(shape=(50,))\n",
        "\n",
        "anchor_output = siamese_model(anchor_input)\n",
        "positive_output = siamese_model(positive_input)\n",
        "negative_output = siamese_model(negative_input)\n",
        "\n",
        "output = layers.Concatenate()([anchor_output, positive_output, negative_output])\n",
        "\n",
        "model = models.Model(inputs=[anchor_input, positive_input, negative_input], outputs =output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rnQk_cckUgn"
      },
      "source": [
        "model.compile(\n",
        "    loss= triplet_loss,\n",
        "    optimizer = Adam()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Sr_gyVkUeC",
        "outputId": "a9ba7964-eb6b-41f1-d4cf-be077728f1af"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 128)          2176128     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 384)          0           sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 2,176,128\n",
            "Trainable params: 2,176,128\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzh3XfEMkfhT",
        "outputId": "b5a19013-1b3b-4ff0-9177-58d7b9fb3782"
      },
      "source": [
        "model.fit([anchor_train, positive_train, negative_train],y_train,\n",
        "          validation_data = ([anchor_dev, positive_dev, negative_dev],y_dev),\n",
        "          epochs=5, \n",
        "          batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "79/79 [==============================] - 217s 3s/step - loss: 0.2491 - val_loss: 0.2069\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 196s 2s/step - loss: 0.1599 - val_loss: 0.1762\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 168s 2s/step - loss: 0.1106 - val_loss: 0.1930\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 187s 2s/step - loss: 0.0819 - val_loss: 0.1956\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 180s 2s/step - loss: 0.0693 - val_loss: 0.2073\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x22e6bf3c550>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8MzkKUAkfb4"
      },
      "source": [
        "def predict(model,input1,input2):\n",
        "    input1 = input1.reshape(50,1)\n",
        "    input2 = input2.reshape(50,1)\n",
        "    output1 = model(input1)\n",
        "    output2 = model(input2)\n",
        "    # print(output1, output2)\n",
        "    # distance = tf.keras.losses.CosineSimilarity(axis=1)\n",
        "    similarity = cos_distance([output1, output2])\n",
        "    # print(similarity)\n",
        "    if similarity >= 0 :\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def cos_distance(vectors):\n",
        "    y_true, y_pred = vectors\n",
        "    def l2_normalize(x, axis):\n",
        "        norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=True))\n",
        "        return K.sign(x) * K.maximum(K.abs(x), K.epsilon()) / K.maximum(norm, K.epsilon())\n",
        "    y_true = l2_normalize(y_true, axis=1)\n",
        "    y_pred = l2_normalize(y_pred, axis=1)\n",
        "    return K.mean(1 - y_true * y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiyTJHu2kj4F"
      },
      "source": [
        "# inference_model= models.load_model('siamese.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY6X9srMkjwL"
      },
      "source": [
        "sent1_tokenize = tokenize(df_test['sentence1'])\n",
        "sent2_tokenize = tokenize(df_test['sentence2'])\n",
        "\n",
        "sent1_tokenize = remove_stopwords(sent1_tokenize)\n",
        "sent2_tokenize = remove_stopwords(sent2_tokenize)\n",
        "\n",
        "sent1_tokenize = stem_word(sent1_tokenize)\n",
        "sent2_tokenize = stem_word(sent2_tokenize)\n",
        "\n",
        "sent1_tokenize = map_to_token(word2idx,sent1_tokenize)\n",
        "sent2_tokenize = map_to_token(word2idx,sent2_tokenize)\n",
        "\n",
        "sent1_tokenize = pad_sequences(sent1_tokenize, maxlen=50)\n",
        "sent2_tokenize = pad_sequences(sent2_tokenize, maxlen=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEWJ6PJWkt4M"
      },
      "source": [
        "# preds = []\n",
        "# for idx in range(20):\n",
        "#     preds.append(predict(siamese_model,sent1_tokenize[idx],sent2_tokenize[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6eTatXykt1c"
      },
      "source": [
        "y = df_test['similarity'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gio8XAkckwLD"
      },
      "source": [
        "preds = np.array(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0SVvsRRAUq"
      },
      "source": [
        "# sum(preds == 1)\n",
        "# len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb-_7TGnkwIJ",
        "outputId": "485644d8-c921-4400-b284-ebd12a73cb81"
      },
      "source": [
        "np.sum(y == preds) / len(sent1_tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Bimal\\AppData\\Local\\Temp/ipykernel_852/343131908.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  np.sum(y == preds) / len(sent1_tokenize)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLInFsz5o6nQ"
      },
      "source": [
        "# for idx in range(100):\n",
        "#     anchor_temp = anchor_train[idx].reshape(1,20)\n",
        "#     positive_temp = positive_train[idx].reshape(1,20)\n",
        "#     negative_temp = negative_train[idx].reshape(1,20)\n",
        "#     print(s_model.predict([anchor_temp,positive_temp ,negative_temp]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW_NXbFR_-ZT"
      },
      "source": [
        "## Contrastive Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JJtDDYyKAAUo",
        "outputId": "9d7c3b0f-14dd-460a-f14d-c553bcbe0ecf"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   similarity                                          sentence1  \\\n",
              "1         0.0  a person on a horse jumps over a broken down a...   \n",
              "2         1.0  a person on a horse jumps over a broken down a...   \n",
              "4         1.0              children smiling and waving at camera   \n",
              "5         0.0              children smiling and waving at camera   \n",
              "6         0.0  a boy is jumping on skateboard in the middle o...   \n",
              "\n",
              "                                     sentence2  \n",
              "1  a person is at a diner ordering an omelette  \n",
              "2              a person is outdoors on a horse  \n",
              "4                   there are children present  \n",
              "5                        the kids are frowning  \n",
              "6             the boy skates down the sidewalk  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>a person on a horse jumps over a broken down a...</td>\n",
              "      <td>a person is at a diner ordering an omelette</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>a person on a horse jumps over a broken down a...</td>\n",
              "      <td>a person is outdoors on a horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>children smiling and waving at camera</td>\n",
              "      <td>there are children present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>children smiling and waving at camera</td>\n",
              "      <td>the kids are frowning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>a boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>the boy skates down the sidewalk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tEU3lmlJOr5B",
        "outputId": "2df6ed03-5058-4272-d2ec-b88c402f5cd7"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   similarity                                          sentence1  \\\n",
              "1         1.0  two women are embracing while holding to go pa...   \n",
              "2         0.0  two women are embracing while holding to go pa...   \n",
              "3         1.0  two young children in blue jerseys one with th...   \n",
              "5         0.0  two young children in blue jerseys one with th...   \n",
              "6         0.0  a man selling donuts to a customer during a wo...   \n",
              "\n",
              "                                       sentence2  \n",
              "1                 two woman are holding packages  \n",
              "2            the men are fighting outside a deli  \n",
              "3  two kids in numbered jerseys wash their hands  \n",
              "5             two kids in jackets walk to school  \n",
              "6      a woman drinks her coffee in a small cafe  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>two women are embracing while holding to go pa...</td>\n",
              "      <td>two woman are holding packages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>two women are embracing while holding to go pa...</td>\n",
              "      <td>the men are fighting outside a deli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>two young children in blue jerseys one with th...</td>\n",
              "      <td>two kids in numbered jerseys wash their hands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>two young children in blue jerseys one with th...</td>\n",
              "      <td>two kids in jackets walk to school</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>a man selling donuts to a customer during a wo...</td>\n",
              "      <td>a woman drinks her coffee in a small cafe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VIlPbmoDOtNp",
        "outputId": "9f2b19d9-7f7d-403c-8119-01281c3091d7"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   similarity                                          sentence1  \\\n",
              "1         1.0  this church choir sings to the masses as they ...   \n",
              "2         0.0  this church choir sings to the masses as they ...   \n",
              "4         1.0  a woman with a green headscarf blue shirt and ...   \n",
              "5         0.0  a woman with a green headscarf blue shirt and ...   \n",
              "6         1.0  an old man with a package poses in front of an...   \n",
              "\n",
              "                            sentence2  \n",
              "1      the church is filled with song  \n",
              "2  a choir singing at a baseball game  \n",
              "4             the woman is very happy  \n",
              "5             the woman has been shot  \n",
              "6       a man poses in front of an ad  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>this church choir sings to the masses as they ...</td>\n",
              "      <td>the church is filled with song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>this church choir sings to the masses as they ...</td>\n",
              "      <td>a choir singing at a baseball game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>a woman with a green headscarf blue shirt and ...</td>\n",
              "      <td>the woman is very happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>a woman with a green headscarf blue shirt and ...</td>\n",
              "      <td>the woman has been shot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>an old man with a package poses in front of an...</td>\n",
              "      <td>a man poses in front of an ad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVaB3KqaOuVx"
      },
      "source": [
        "train_sent1 = df_train['sentence1'].tolist()\n",
        "train_sent2 = df_train['sentence2'].tolist()\n",
        "\n",
        "dev_sent1 = df_dev['sentence1'].tolist()\n",
        "dev_sent2 = df_dev['sentence2'].tolist()\n",
        "\n",
        "test_sent1 = df_test['sentence1'].tolist()\n",
        "test_sent2 = df_test['sentence2'].tolist()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht7fODL6Pdz_"
      },
      "source": [
        "train_label = df_train['similarity'].tolist()\n",
        "dev_label = df_dev['similarity'].tolist()\n",
        "test_label = df_test['similarity'].tolist()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwNN1r0GOzEx"
      },
      "source": [
        "train_sent1 = train_sent1[:100000]\n",
        "train_sent2 = train_sent2[:100000]\n",
        "train_label = train_label[:100000]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_puqcztPAM5"
      },
      "source": [
        "train_sent1_tokens = tokenize(train_sent1)\n",
        "train_sent2_tokens = tokenize(train_sent2)\n",
        "\n",
        "dev_sent1_tokens = tokenize(dev_sent1)\n",
        "dev_sent2_tokens = tokenize(dev_sent2)\n",
        "\n",
        "test_sent1_tokens = tokenize(test_sent1)\n",
        "test_sent2_tokens = tokenize(test_sent2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoxt6LXmP1Ya"
      },
      "source": [
        "train_sent1_tokens = remove_stopwords(train_sent1_tokens)\n",
        "train_sent2_tokens = remove_stopwords(train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = remove_stopwords(dev_sent1_tokens)\n",
        "dev_sent2_tokens = remove_stopwords(dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = remove_stopwords(test_sent1_tokens)\n",
        "test_sent2_tokens = remove_stopwords(test_sent2_tokens)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOLkvTTrQGdi"
      },
      "source": [
        "train_sent1_tokens = stem_word(train_sent1_tokens)\n",
        "train_sent2_tokens = stem_word(train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = stem_word(dev_sent1_tokens)\n",
        "dev_sent2_tokens = stem_word(dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = stem_word(test_sent1_tokens)\n",
        "test_sent2_tokens = stem_word(test_sent2_tokens)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEAOT6RtQxWP"
      },
      "source": [
        "def create_vocabulary_contra(sentence1, sentence2):\n",
        "    sentence1 = set(flatten(sentence1))\n",
        "    sentence2 = set(flatten(sentence2))\n",
        "    vocab = sentence1.union(sentence2)\n",
        "    return sorted(list(vocab))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SReffN7NQNHB"
      },
      "source": [
        "vocab = create_vocabulary_contra(train_sent1_tokens, train_sent2_tokens)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jhYFshfQ-FJ"
      },
      "source": [
        "word2idx, idx2word = create_mappings(vocab)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5BRYDowQ-lJ"
      },
      "source": [
        "train_sent1_tokens = map_to_token(word2idx,train_sent1_tokens)\n",
        "train_sent2_tokens = map_to_token(word2idx,train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = map_to_token(word2idx,dev_sent1_tokens)\n",
        "dev_sent2_tokens = map_to_token(word2idx,dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = map_to_token(word2idx,test_sent1_tokens)\n",
        "test_sent2_tokens = map_to_token(word2idx,test_sent2_tokens)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBTxS-R6RYXK"
      },
      "source": [
        "train_data1 = pad_sequences(train_sent1_tokens, maxlen=50)\n",
        "train_data2 = pad_sequences(train_sent2_tokens,maxlen=50)\n",
        "\n",
        "dev_data1 = pad_sequences(dev_sent1_tokens, maxlen=50)\n",
        "dev_data2 = pad_sequences(dev_sent2_tokens,maxlen=50)\n",
        "\n",
        "test_data1 = pad_sequences(test_sent1_tokens, maxlen=50)\n",
        "test_data2 = pad_sequences(test_sent2_tokens,maxlen=50)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojv-KAEuRqr5"
      },
      "source": [
        "train_data1 = np.array(train_data1, dtype='object').astype('float')\n",
        "train_data2 = np.array(train_data2, dtype='object').astype('float')\n",
        "train_label = np.array(train_label).astype(\"float\")\n",
        "\n",
        "dev_data1 = np.array(dev_data1, dtype='object').astype('float')\n",
        "dev_data2 = np.array(dev_data2, dtype='object').astype('float')\n",
        "dev_label = np.array(dev_label).astype(\"float\")\n",
        "\n",
        "test_data1 = np.array(test_data1, dtype='object').astype('float')\n",
        "test_data2 = np.array(test_data2, dtype='object').astype('float')\n",
        "test_label = np.array(test_label).astype(\"float\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0phIx_L8T3_S"
      },
      "source": [
        "def contrastive_loss(y, preds, margin=1):\n",
        "    # explicitly cast the true class label data type to the predicted\n",
        "    # class label data type (otherwise we run the risk of having two\n",
        "    # separate data types, causing TensorFlow to error out)\n",
        "    y = tf.cast(y, preds.dtype)\n",
        "    # calculate the contrastive loss between the true labels and\n",
        "    # the predicted labels\n",
        "    squaredPreds = K.square(preds)\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "    # return the computed contrastive loss to the calling function\n",
        "    return loss"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_smykUR5T455"
      },
      "source": [
        "def euclidean_distance(vectors):\n",
        "    # unpack the vectors into separate lists\n",
        "    (featsA, featsB) = vectors\n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5H1rtxgbkH3"
      },
      "source": [
        "def cos_distance(vectors):\n",
        "    y_true, y_pred = vectors\n",
        "    def l2_normalize(x, axis):\n",
        "        norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=True))\n",
        "        return K.sign(x) * K.maximum(K.abs(x), K.epsilon()) / K.maximum(norm, K.epsilon())\n",
        "    y_true = l2_normalize(y_true, axis=-1)\n",
        "    y_pred = l2_normalize(y_pred, axis=-1)\n",
        "    return K.mean(y_true * y_pred, axis=-1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDVhGQTIT_MC"
      },
      "source": [
        "base_model = models.Sequential()\n",
        "base_model.add(layers.Embedding(input_dim=len(vocab)+2, output_dim=100))\n",
        "base_model.add(layers.LSTM(100, return_sequences=True))\n",
        "base_model.add(layers.Dropout(0.3))\n",
        "base_model.add(layers.GlobalAveragePooling1D())\n",
        "base_model.add(layers.Dense(128, activation='relu'))\n",
        "base_model.add(layers.Dense(100, activation='relu'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBpLpU5rUBsy",
        "outputId": "cd9705d1-13f0-4365-f820-f70222ce42a8"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1127700   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 1,233,928\n",
            "Trainable params: 1,233,928\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdUJ1QMUE6h"
      },
      "source": [
        "input1 = keras.Input(shape=(train_data1.shape[1],))\n",
        "input2 = keras.Input(shape=(train_data1.shape[1],))\n",
        "\n",
        "encoding1 = base_model(input1)\n",
        "encoding2 = base_model(input2)\n",
        "\n",
        "distance = layers.Concatenate()([encoding1, encoding2])\n",
        "# distance = layers.Lambda(euclidean_distance)([encoding1, encoding2])\n",
        "dense1 = layers.Dense(128, activation='relu')(distance)\n",
        "dropout1 = layers.Dropout(0.2)(dense1)\n",
        "dense2 = layers.Dense(128, activation='relu')(dropout1)\n",
        "final = layers.Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "model = models.Model(inputs = [input1, input2], outputs = final)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgMzky14UHUy",
        "outputId": "f8fc6089-3788-4e3b-96e6-1d01172a990f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 100)          1233928     input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 200)          0           sequential_1[0][0]               \n",
            "                                                                 sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          25728       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            129         dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,259,785\n",
            "Trainable params: 1,259,785\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZdaEE8OUMaQ"
      },
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfEM1214UPN-",
        "outputId": "e7b3bdf3-f067-4908-93df-9b748c9ad486"
      },
      "source": [
        "model.fit(\n",
        "    [train_data1,train_data2],\n",
        "    train_label,\n",
        "    batch_size=64,\n",
        "    validation_data=([dev_data1,dev_data2], dev_label), \n",
        "    epochs=5\n",
        "    )"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 174s 109ms/step - loss: 0.6398 - accuracy: 0.5734 - val_loss: 0.4840 - val_accuracy: 0.7537\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 173s 111ms/step - loss: 0.4554 - accuracy: 0.7735 - val_loss: 0.4515 - val_accuracy: 0.7775\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 178s 114ms/step - loss: 0.4062 - accuracy: 0.8096 - val_loss: 0.4314 - val_accuracy: 0.8008\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 172s 110ms/step - loss: 0.3722 - accuracy: 0.8324 - val_loss: 0.4211 - val_accuracy: 0.8035\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 154s 99ms/step - loss: 0.3470 - accuracy: 0.8464 - val_loss: 0.4305 - val_accuracy: 0.8010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x22b79082e80>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AMIEIeUZVYh"
      },
      "source": [
        "model.save('binary_loss_model1.h5')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sRNjjbLUsZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f22ffa-0a56-4224-ff51-9ce416c4dcc6"
      },
      "source": [
        "model.predict([test_data1,test_data2])[1][0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39341095"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XME2QWsaNfi"
      },
      "source": [
        "def predict():\n",
        "    preds = model.predict([test_data1,test_data2])\n",
        "    preds_list = [1 if p[0] >= 0.5 else 0 for p in preds ]\n",
        "    return preds_list"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJQDSDkrapIz"
      },
      "source": [
        "preds = predict()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnbJ0Pejawzk",
        "outputId": "0bd7bbf1-f37a-4cdc-94c4-1bef30ba3f7b"
      },
      "source": [
        "sum(test_label == preds) / len(preds)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7990915972747918"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "waiN7j8nBwAA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_label, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1-YpJetB60o",
        "outputId": "b82bd553-16a1-42dd-bf2f-7726baf91c5b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.75      0.79      3237\n",
            "         1.0       0.78      0.84      0.81      3368\n",
            "\n",
            "    accuracy                           0.80      6605\n",
            "   macro avg       0.80      0.80      0.80      6605\n",
            "weighted avg       0.80      0.80      0.80      6605\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "iK4-t1aMCGIo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(test_label, preds)"
      ],
      "metadata": {
        "id": "7NGyqx5UCJbx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Yhp4CZW2CQcV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_mat)"
      ],
      "metadata": {
        "id": "tnbL2NLaCUYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwVXwf-i4NE"
      },
      "source": [
        "def cos_distance(y_true, y_pred):\n",
        "    #y_true = K.l2_normalize(y_true, axis=-1)\n",
        "    #y_pred = K.l2_normalize(y_pred, axis=-1)\n",
        "    return K.mean(1 - K.sum((y_true * y_pred), axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjhMRz_YS0pu"
      },
      "source": [
        "## Triplet loss with just positive examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pCQXrt-S6EF"
      },
      "source": [
        "df_train_pos = df_train.loc[(df_train['similarity'] == 1)]\n",
        "df_dev_pos = df_dev.loc[(df_dev['similarity'] == 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmf7L5WrS7Nz",
        "outputId": "770af3cd-a0b3-482a-b350-fb9005bab2de"
      },
      "source": [
        "df_train_pos.drop_duplicates(inplace=True)\n",
        "df_dev_pos.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZtGnyojaHOr"
      },
      "source": [
        "train_sent1 = df_train_pos['sentence1'].tolist()\n",
        "train_sent2 = df_train_pos['sentence2'].tolist()\n",
        "\n",
        "dev_sent1 = df_dev_pos['sentence1'].tolist()\n",
        "dev_sent2 = df_dev_pos['sentence2'].tolist()\n",
        "\n",
        "test_sent1 = df_test['sentence1'].tolist()\n",
        "test_sent2 = df_test['sentence2'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyhcOLCUaeBd"
      },
      "source": [
        "train_label = df_train_pos['similarity'].tolist()\n",
        "dev_label = df_dev_pos['similarity'].tolist()\n",
        "test_label = df_test['similarity'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPi93Jsbad-7"
      },
      "source": [
        "train_sent1 = train_sent1[:100000]\n",
        "train_sent2 = train_sent2[:100000]\n",
        "train_label = train_label[:100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91BPBAPAad8f"
      },
      "source": [
        "train_sent1_tokens = tokenize(train_sent1)\n",
        "train_sent2_tokens = tokenize(train_sent2)\n",
        "\n",
        "dev_sent1_tokens = tokenize(dev_sent1)\n",
        "dev_sent2_tokens = tokenize(dev_sent2)\n",
        "\n",
        "test_sent1_tokens = tokenize(test_sent1)\n",
        "test_sent2_tokens = tokenize(test_sent2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfSK-rxMad5_"
      },
      "source": [
        "train_sent1_tokens = remove_stopwords(train_sent1_tokens)\n",
        "train_sent2_tokens = remove_stopwords(train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = remove_stopwords(dev_sent1_tokens)\n",
        "dev_sent2_tokens = remove_stopwords(dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = remove_stopwords(test_sent1_tokens)\n",
        "test_sent2_tokens = remove_stopwords(test_sent2_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n62EWL9ead3m"
      },
      "source": [
        "train_sent1_tokens = stem_word(train_sent1_tokens)\n",
        "train_sent2_tokens = stem_word(train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = stem_word(dev_sent1_tokens)\n",
        "dev_sent2_tokens = stem_word(dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = stem_word(test_sent1_tokens)\n",
        "test_sent2_tokens = stem_word(test_sent2_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_67lhjKawSk"
      },
      "source": [
        "vocab = create_vocabulary_contra(train_sent1_tokens, train_sent2_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Rrb2aCa4ik"
      },
      "source": [
        "word2idx, idx2word = create_mappings(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikggOcpsa4f4"
      },
      "source": [
        "train_sent1_tokens = map_to_token(word2idx,train_sent1_tokens)\n",
        "train_sent2_tokens = map_to_token(word2idx,train_sent2_tokens)\n",
        "\n",
        "dev_sent1_tokens = map_to_token(word2idx,dev_sent1_tokens)\n",
        "dev_sent2_tokens = map_to_token(word2idx,dev_sent2_tokens)\n",
        "\n",
        "test_sent1_tokens = map_to_token(word2idx,test_sent1_tokens)\n",
        "test_sent2_tokens = map_to_token(word2idx,test_sent2_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soT_pUpra4db"
      },
      "source": [
        "train_data1 = pad_sequences(train_sent1_tokens, maxlen=50)\n",
        "train_data2 = pad_sequences(train_sent2_tokens,maxlen=50)\n",
        "\n",
        "dev_data1 = pad_sequences(dev_sent1_tokens, maxlen=50)\n",
        "dev_data2 = pad_sequences(dev_sent2_tokens,maxlen=50)\n",
        "\n",
        "test_data1 = pad_sequences(test_sent1_tokens, maxlen=50)\n",
        "test_data2 = pad_sequences(test_sent2_tokens,maxlen=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2fi8e8obDw0"
      },
      "source": [
        "train_data1 = np.array(train_data1, dtype='object').astype('int32')\n",
        "train_data2 = np.array(train_data2, dtype='object').astype('int32')\n",
        "train_label = np.array(train_label).astype(\"int32\")\n",
        "\n",
        "dev_data1 = np.array(dev_data1, dtype='object').astype('int32')\n",
        "dev_data2 = np.array(dev_data2, dtype='object').astype('int32')\n",
        "dev_label = np.array(dev_label).astype(\"int32\")\n",
        "\n",
        "test_data1 = np.array(test_data1, dtype='object').astype('int32')\n",
        "test_data2 = np.array(test_data2, dtype='object').astype('int32')\n",
        "test_label = np.array(test_label).astype(\"int32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsQGYonbovy"
      },
      "source": [
        "def calculate_mean(x, axis=1):\n",
        "    return K.mean(x, axis=axis)\n",
        "\n",
        "def normalize(x):\n",
        "        return x / K.sqrt(K.sum(x * x, axis=-1, keepdims=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXJHiUobHbM"
      },
      "source": [
        "base_model = tf.keras.Sequential()\n",
        "base_model.add(tf.keras.layers.Embedding(input_dim=len(vocab)+2, output_dim=128))\n",
        "base_model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "base_model.add(tf.keras.layers.Lambda(calculate_mean, name='mean'))\n",
        "base_model.add(tf.keras.layers.Lambda(normalize, name='normalize'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4msJ73VcOVT",
        "outputId": "48de3f23-419a-4a3f-ae87-272be6a533a7"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 128)         1497856   \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, None, 128)         131584    \n",
            "_________________________________________________________________\n",
            "mean (Lambda)                (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "normalize (Lambda)           (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 1,629,440\n",
            "Trainable params: 1,629,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb_l3Y8KbHYd"
      },
      "source": [
        "input1 = tf.keras.layers.Input(shape=(50,))\n",
        "input2 = tf.keras.layers.Input(shape=(50,))\n",
        "\n",
        "encoding1 = base_model(input1)\n",
        "encoding2 = base_model(input2)\n",
        "\n",
        "merged = tf.keras.layers.Concatenate()([encoding1, encoding2])\n",
        "\n",
        "model = tf.keras.Model(inputs = [input1, input2], outputs = merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-v4cuvGce-_",
        "outputId": "fcde1011-d751-47c5-e459-25cb95db8e09"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_9 (Sequential)       (None, 128)          1629440     input_21[0][0]                   \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 256)          0           sequential_9[0][0]               \n",
            "                                                                 sequential_9[1][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,629,440\n",
            "Trainable params: 1,629,440\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1kyAdrSTIg7"
      },
      "source": [
        "def TripletLoss(margin=0.25):\n",
        "    def triplet(y_true,y_pred):\n",
        "      batch_size = tf.cast(tf.shape(y_true)[0], dtype=tf.float32)\n",
        "      v1, v2 = y_pred[:,:128],y_pred[:,-128:]\n",
        "      scores = K.dot(v1, K.transpose(v2))\n",
        "      positive = tf.linalg.diag_part(scores)\n",
        "      negative_without_positive = scores - 2 * tf.eye(batch_size)\n",
        "\n",
        "      closest_negative = tf.reduce_max(negative_without_positive, axis=1)\n",
        "\n",
        "      negative_zero_on_duplicate = scores * (1.0 - tf.eye(batch_size))\n",
        "      \n",
        "      mean_negative = K.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
        "      \n",
        "      triplet_loss1 = K.maximum(0.0, margin - positive + closest_negative)\n",
        "      \n",
        "      triplet_loss2 = K.maximum(0.0, margin - positive + mean_negative)\n",
        "      \n",
        "      triplet_loss = K.mean(triplet_loss1 + triplet_loss2)\n",
        "\n",
        "      return triplet_loss\n",
        "    return triplet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6aX-0AocmR3"
      },
      "source": [
        "triplet_loss = TripletLoss()\n",
        "model.compile(\n",
        "    optimizer = Adam(0.001),\n",
        "    loss = triplet_loss\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cqzRKp6ctE-",
        "outputId": "0c21c129-161d-40aa-fdbd-14a84bd3767b"
      },
      "source": [
        "history = model.fit(\n",
        "    [train_data1,train_data2],\n",
        "    train_label,\n",
        "    batch_size=64,\n",
        "    validation_data=([dev_data1,dev_data2], dev_label), \n",
        "    epochs=5\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 248s 154ms/step - loss: 0.2072 - val_loss: 0.1516\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 255s 163ms/step - loss: 0.0988 - val_loss: 0.1422\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 259s 166ms/step - loss: 0.0818 - val_loss: 0.1410\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 261s 167ms/step - loss: 0.0733 - val_loss: 0.1419\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 261s 167ms/step - loss: 0.0690 - val_loss: 0.1405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuGxQmEGLboS"
      },
      "source": [
        "def predict(model, sentence1, sentence2, cosine=False):\n",
        "    sentence1 = sentence1.reshape(1,50)\n",
        "    sentence2 = sentence2.reshape(1,50)\n",
        "    v = model.predict([sentence1, sentence2])\n",
        "    v1, v2 = v[:,:128], v[:,-128:]\n",
        "    similarity = np.dot(v1,v2.T)[0][0]\n",
        "    if similarity >= 0.65:\n",
        "        return 1\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHWXAHgJWrA4"
      },
      "source": [
        "preds = []\n",
        "for idx in range(len(test_data1)):\n",
        "    preds.append(predict(model,test_data1[idx], test_data2[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyHCp-KFYBwI",
        "outputId": "cdb21174-f0d3-46f5-b6a9-f41a85acce99"
      },
      "source": [
        "sum(test_label == preds) / len(test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6825132475397426"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJgrxHOFZ646"
      },
      "source": [
        "model.save(\"Triplet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91T9eI6-qy30"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}